{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CRpRB8aw2XWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4aff2d9-b85a-4c04-e7e0-a5254f874e24"
      },
      "id": "CRpRB8aw2XWN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b6a615",
      "metadata": {
        "id": "92b6a615"
      },
      "source": [
        "# 1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ae6519e7",
      "metadata": {
        "id": "ae6519e7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action = \"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384425e1",
      "metadata": {
        "id": "384425e1"
      },
      "source": [
        "# 2. Config Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ea203604",
      "metadata": {
        "id": "ea203604"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "config = {\"data_path\":\"/content/drive/MyDrive/23Inha_AI_RecSys/data\",\n",
        "          \"model_path\":\"/content/drive/MyDrive/23Inha_AI_RecSys/model/model.pth\",\n",
        "          \"submit_path\":\"/content/drive/MyDrive/23Inha_AI_RecSys/submit/submit_autorec.csv\",\n",
        "          \"n_valid_sample\":2, #검증 샘플 비율 or 개수\n",
        "          \"replace\":True, #검증 샘플 복원 / 비복원 추출\n",
        "\n",
        "          \"epoch\":30,\n",
        "          \"lr\":5e-4,    # best | 5e-4 at epoch 13\n",
        "          \"batch_size\":1024,\n",
        "          \"threshold\":0., #평점 임계값\n",
        "\n",
        "          \"n_feature\":128, # AutoRec 모델의 특성 차원 설정\n",
        "\n",
        "          \"top_k\":50, # 추천 결과에서 상위 K개 아이템을 선택하기 위한 K 값 설정\n",
        "\n",
        "          \"seed\":39,  # 재현성을 위한 난수 시드 설정\n",
        "          \"n_workers\":2} # 데이터 로딩을 위한 병렬 작업자 수 설정\n",
        "\n",
        "fix_seed(config[\"seed\"])\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "os.makedirs(os.path.dirname(config[\"model_path\"]), exist_ok = True)\n",
        "os.makedirs(os.path.dirname(config[\"submit_path\"]), exist_ok = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8eb35b",
      "metadata": {
        "id": "ba8eb35b"
      },
      "source": [
        "# 3. Data Preprocessing\n",
        "- Rating 정보인 train.csv, Image / Review 정보인 image / text.npy, Label 정보인 user / item_label.npy로 구성\n",
        "- image.npy에는 제품 별 Image를 CNN을 통해 가공한 Feature 제공\n",
        "- text.npy에는 제품 별 Review를 Transformer를 통해 가공한 Feature 제공\n",
        "- 단, image feature는 Memory Overflow 문제가 발생할 수 있어, 20000개 단위로 Split한 image_1-N.npy를 함께 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a3eff5a4",
      "metadata": {
        "id": "a3eff5a4"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "    def __init__(self, path, n_valid_sample = 1, threshold = 0., replace = False, seed = 0):\n",
        "        \"\"\"\n",
        "                 user    item    interaction sparsity\n",
        "        data     192,403 63,001  1,689,188   99.9861%\n",
        "\n",
        "        rating scale - 1-5\n",
        "        review feature shape - (I, 384)\n",
        "        image feature shape - (I, 4096)\n",
        "        \"\"\"\n",
        "        self.path = os.path.join(path, \"train.csv\")\n",
        "        self.n_valid_sample = n_valid_sample\n",
        "        self.threshold = threshold\n",
        "        self.replace = replace\n",
        "        self.seed = seed\n",
        "\n",
        "        #rating > (N, [user id, item id, rating])\n",
        "        self.raw_data = self.parse(self.path)\n",
        "        self.tr_data, self.te_data = self.split_data(self.raw_data, n_sample = self.n_valid_sample, replace = self.replace, seed = self.seed)\n",
        "\n",
        "        #tag > (item id, feature)\n",
        "        #self.image = parse(os.path.join(path, \"image.npy\")) #image_1-N.npy > image.npy load시 memory overflow가 나는 경우를 위해, 20000개 단위 Split\n",
        "        #self.text = parse(os.path.join(path, \"text.npy\"))\n",
        "\n",
        "        self.user_label = np.load(os.path.join(path, \"user_label.npy\"))\n",
        "        self.item_label = np.load(os.path.join(path, \"item_label.npy\"))\n",
        "        self.user_encoder, self.user_decoder = self.generate_label_mapper(self.user_label)\n",
        "        self.item_encoder, self.item_decoder = self.generate_label_mapper(self.item_label)\n",
        "        self.tr_data = self.map_label(self.tr_data, self.user_encoder, self.item_encoder)\n",
        "        self.te_data = self.map_label(self.te_data, self.user_encoder, self.item_encoder)\n",
        "\n",
        "        self.tr_pos, self.tr_neg = self.generate_sequence_data(self.tr_data)\n",
        "        self.te_pos, self.te_neg = self.generate_sequence_data(self.te_data, 3) #3점 이상인 경우 Positive\n",
        "\n",
        "        self.exist_users = [i for i in range(len(self.user_label))]\n",
        "        self.exist_items = [i for i in range(len(self.item_label))]\n",
        "\n",
        "        self.random = np.random.RandomState(seed = self.seed)\n",
        "\n",
        "    @staticmethod\n",
        "    def parse(path):\n",
        "        data = pd.read_csv(path).to_numpy()\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def split_data(data, n_sample = 1, replace = False, seed = None):\n",
        "        \"\"\"\n",
        "        train / valid data로 split\n",
        "\n",
        "        Args:\n",
        "            data\n",
        "        Returns:\n",
        "            train data / valid data\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        ratings = defaultdict(list)\n",
        "        user_train = []\n",
        "        user_valid = []\n",
        "        for d in data:\n",
        "            users[int(d[0])].append(d[1])\n",
        "            ratings[int(d[0])].append(d[2])\n",
        "\n",
        "        random = (np.random.RandomState(seed) if seed is not None else np.random)\n",
        "        for user in users:\n",
        "            item, rating = users[user], ratings[user]\n",
        "            n_valid_sample = max(int(np.round(len(item) * n_sample)) if isinstance(n_sample, float) else min(n_sample, len(item)), 1)\n",
        "            n_valid_sample = (n_valid_sample - 1) if (len(item) == n_valid_sample) else n_valid_sample\n",
        "            valid_indices = random.choice(len(item), size = n_valid_sample, replace = replace).tolist()\n",
        "            valid = [item[i] for i in valid_indices]\n",
        "            train = list(set(item) - set(valid))\n",
        "            train_indices = [idx for idx, i in enumerate(item) if i in train]\n",
        "\n",
        "            for i, r in zip(train, [rating[i] for i in train_indices]):\n",
        "                user_train.append([user, i, r])\n",
        "\n",
        "            for i, r in zip(valid, [rating[i] for i in valid_indices]):\n",
        "                user_valid.append([user, i, r])\n",
        "        user_train = np.array(user_train, dtype = data.dtype)\n",
        "        user_valid = np.array(user_valid, dtype = data.dtype)\n",
        "        return user_train, user_valid\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_label_mapper(label):\n",
        "        \"\"\"\n",
        "        mapper 생성\n",
        "\n",
        "        Args:\n",
        "            id list\n",
        "        Returns:\n",
        "            dict: 생성된 label encoder, decoder\n",
        "        \"\"\"\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        for idx, _id in enumerate(label):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "        return encoder, decoder\n",
        "\n",
        "    @staticmethod\n",
        "    def map_label(data, user_mapper, item_mapper):\n",
        "        return np.array([[user_mapper[d[0]], item_mapper[d[1]], d[2]] for d in data], dtype = data.dtype)\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_sequence_data(data, threshold = 0.):\n",
        "        \"\"\"\n",
        "        sequence_data 생성\n",
        "\n",
        "        Returns:\n",
        "            dict: user 별 pos item sequence, neg item sequence\n",
        "        \"\"\"\n",
        "        pos_users = defaultdict(list)\n",
        "        neg_users = defaultdict(list)\n",
        "        pos_ratings = defaultdict(list)\n",
        "        neg_ratings = defaultdict(list)\n",
        "        for d in data:\n",
        "            if threshold <= d[2]: #설정한 임계 평점 값 기준으로 높으면 positive\n",
        "                pos_users[int(d[0])].append(int(d[1]))\n",
        "                neg_users[int(d[0])]\n",
        "                pos_ratings[int(d[0])].append(d[2])\n",
        "                neg_ratings[int(d[0])]\n",
        "            else:  #설정한 임계 평점 값 기준으로 낮으면 negative\n",
        "                pos_users[int(d[0])]\n",
        "                neg_users[int(d[0])].append(int(d[1]))\n",
        "                pos_ratings[int(d[0])]\n",
        "                neg_ratings[int(d[0])].append(d[2])\n",
        "        for user in list(pos_users.keys()):\n",
        "            items = pos_users[user]\n",
        "            pos_users[user] = [items[i] for i in np.argsort(pos_ratings[user])[::-1]]\n",
        "            items = neg_users[user]\n",
        "            neg_users[user] = [items[i] for i in np.argsort(neg_ratings[user])[::-1]]\n",
        "        return pos_users, neg_users #각 유저 별 긍, 부정 아이템 시퀀스\n",
        "\n",
        "    def neg_sampling(self, users, sampling_count = 4):\n",
        "        \"\"\"\n",
        "        음성 샘플링을 수행하여 사용자와 함께 반환\n",
        "\n",
        "        Args:\n",
        "            users (numpy.ndarray): 사용자 배열\n",
        "            sampling_count (int): 음성 샘플링 개수\n",
        "\n",
        "        Returns:\n",
        "            list, list: 음성 사용자 배열, 음성 아이템 배열\n",
        "        \"\"\"\n",
        "        _users, neg_items = [], []\n",
        "        for user in users:\n",
        "            neg = self.tr_neg[user]\n",
        "            neg = self.random.choice(neg, min(sampling_count, len(neg)), replace = False).tolist() if 0 < len(neg) else []\n",
        "            if len(neg) < sampling_count:\n",
        "                new_neg = list(set(self.exist_items) - set(self.tr_pos[user]))\n",
        "                new_neg = self.random.choice(new_neg, sampling_count - len(neg), replace = False)\n",
        "                neg = np.concatenate([neg, new_neg]).astype(np.int32).tolist()\n",
        "            neg_items += neg\n",
        "            _users += [user] * len(neg)\n",
        "        return _users, neg_items\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self.tr_pos, self.te_pos\n",
        "\n",
        "    def to_matrix(self, data, users):\n",
        "        \"\"\"\n",
        "        autorec모델 학습을 위해 데이터를 행렬 형태로 변환.\n",
        "        \"\"\"\n",
        "        mat = torch.zeros(users.size(0), len(self.item_label))\n",
        "        for i, user in enumerate(users):\n",
        "            j = data[user.item()]\n",
        "            mat[i, j] = 1\n",
        "        return mat\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, n_user):\n",
        "        self.n_user = n_user\n",
        "        self.users = [i for i in range(n_user)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_user\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.LongTensor([self.users[i]])\n",
        "\n",
        "parser = Parser(config[\"data_path\"], config[\"n_valid_sample\"], config[\"threshold\"], config[\"replace\"], config[\"seed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e46b10b",
      "metadata": {
        "id": "5e46b10b"
      },
      "source": [
        "# 4. Define Model\n",
        "- AutoRec(https://dl.acm.org/doi/10.1145/2740908.2742726)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d2bf438a",
      "metadata": {
        "id": "d2bf438a"
      },
      "outputs": [],
      "source": [
        "class AutoRec(nn.Module):\n",
        "    def __init__(self, n_item, n_feature, dropout=0.1):\n",
        "        super(AutoRec, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(n_item, n_feature),  # 입력 크기인 n_item에서 n_feature로 이어지는 선형 레이어\n",
        "            nn.Sigmoid(),\n",
        "            #nn.Linear(n_feature, n_feature // 4),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            #nn.Linear(n_feature // 4, n_feature),\n",
        "            #nn.Identity(),\n",
        "            nn.Linear(n_feature, n_item), # n_feature에서 n_item으로 이어지는 선형 레이어\n",
        "            nn.Identity()\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, mat):\n",
        "        latent = self.dropout(self.encoder(mat)) # 입력 데이터를 인코더에 전달하여 잠재 특성을 얻음\n",
        "        recont_mat = self.decoder(latent) # 잠재 특성을 디코더에 전달하여 재구성 행렬을 얻음\n",
        "        return recont_mat\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        인코더와 디코더의 가중치를 초기화하는 함수.\n",
        "        \"\"\"\n",
        "        for layer in self.encoder:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                size = layer.weight.size()\n",
        "                fan_out = size[0]\n",
        "                fan_in = size[1]\n",
        "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "                layer.weight.data.normal_(0.0, std)\n",
        "                layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "        for layer in self.decoder:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                size = layer.weight.size()\n",
        "                fan_out = size[0]\n",
        "                fan_in = size[1]\n",
        "                std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "                layer.weight.data.normal_(0.0, std)\n",
        "                layer.bias.data.normal_(0.0, 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da41ffcb",
      "metadata": {
        "id": "da41ffcb"
      },
      "source": [
        "# 5. Experimental Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a234aca",
      "metadata": {
        "id": "3a234aca"
      },
      "outputs": [],
      "source": [
        "def ndcg(true_list, pred_list):  # NDCG (Normalized Discounted Cumulative Gain) 계산 함수\n",
        "    true_list = true_list[:len(pred_list)]\n",
        "    idcg = 1 / np.log2(np.arange(len(true_list)) + 2)\n",
        "    dcg = 1 / np.log2([rank + 2 for rank, pred in enumerate(pred_list) if pred in true_list])\n",
        "    return np.sum(dcg) / (np.sum(idcg) + 1e-12)\n",
        "\n",
        "def train(model, data_loader, criterion, optimizer, parser, prefix = \"\", leave = True):\n",
        "    prefix = prefix + \" | \" if len(prefix) != 0 else prefix\n",
        "\n",
        "    model.train()\n",
        "    loss_val = 0\n",
        "\n",
        "    tbar = tqdm(data_loader, total = len(data_loader), leave = leave)\n",
        "    try:\n",
        "        for i, users in enumerate(tbar):\n",
        "            mat = parser.to_matrix(tr_pos, users)\n",
        "            mat = mat.to(device)\n",
        "            recon_mat = model(mat)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(recon_mat, mat)\n",
        "\n",
        "            loss = torch.sqrt(loss)     # *** modify HERE ***\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_val += loss.item()\n",
        "            tbar.set_description(\"{0}tr_loss: {1:.4e}\".format(prefix, loss_val / (i + 1)))\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "    finally:\n",
        "        tbar.close()\n",
        "    loss_val /= len(data_loader)\n",
        "    return loss_val\n",
        "\n",
        "def evaluate(model, data_loader, parser, k = 50, prefix = \"\", leave = True):\n",
        "    prefix = prefix + \" | \" if len(prefix) != 0 else prefix\n",
        "    model.eval()\n",
        "\n",
        "    NDCG = 0.0\n",
        "\n",
        "    tr_pos, te_pos = parser.data\n",
        "\n",
        "    tbar = tqdm(data_loader, total = len(data_loader), leave = leave)\n",
        "    cnt = 0\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for i, users in enumerate(tbar):\n",
        "                mat = parser.to_matrix(tr_pos, users)\n",
        "                mat = mat.to(device)\n",
        "\n",
        "                recon_mat = model(mat)\n",
        "                recon_mat = recon_mat.softmax(dim = 1)\n",
        "                recon_mat[mat == 1] = -1.\n",
        "                rec_list = recon_mat.argsort(dim = 1)\n",
        "\n",
        "                for user, rec in zip(users, rec_list):\n",
        "                    uv = te_pos[user.item()]\n",
        "                    up = rec[-k:].cpu().numpy()[::-1].tolist()\n",
        "                    NDCG += ndcg(true_list = uv, pred_list = up)\n",
        "                    cnt += 1\n",
        "                tbar.set_description(\"{0}ndcg: {1:.4f}\".format(prefix, NDCG / cnt))\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "    finally:\n",
        "        tbar.close()\n",
        "    NDCG /= cnt\n",
        "    return NDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01554896",
      "metadata": {
        "id": "01554896"
      },
      "outputs": [],
      "source": [
        "tr_pos, te_pos = parser.data\n",
        "tr_ds = Dataset(len(parser.user_label))\n",
        "tr_loader = DataLoader(tr_ds, batch_size = config[\"batch_size\"], shuffle = True, drop_last = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "49ff5389",
      "metadata": {
        "id": "49ff5389"
      },
      "outputs": [],
      "source": [
        "model = AutoRec(n_item = len(parser.item_label),\n",
        "                n_feature = config[\"n_feature\"]).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config[\"lr\"])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beac412c",
      "metadata": {
        "id": "beac412c"
      },
      "source": [
        "# 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f3529cbf",
      "metadata": {
        "id": "f3529cbf",
        "outputId": "140273ae-e682-43a4-920f-27453dbe51b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 001/030 | tr_loss: 7.0024e+00 | ndcg: 0.0186: 100%|██████████| 188/188 [00:39<00:00,  4.77it/s]\n",
            "epoch: 002/030 | tr_loss: 6.9248e+00 | ndcg: 0.0187: 100%|██████████| 188/188 [00:39<00:00,  4.76it/s]\n",
            "epoch: 003/030 | tr_loss: 6.9196e+00 | ndcg: 0.0186: 100%|██████████| 188/188 [00:39<00:00,  4.75it/s]\n",
            "epoch: 004/030 | tr_loss: 6.9158e+00 | ndcg: 0.0187: 100%|██████████| 188/188 [00:39<00:00,  4.73it/s]\n",
            "epoch: 005/030 | tr_loss: 6.9102e+00 | ndcg: 0.0188: 100%|██████████| 188/188 [00:39<00:00,  4.76it/s]\n",
            "epoch: 006/030 | tr_loss: 6.9015e+00 | ndcg: 0.0188: 100%|██████████| 188/188 [00:39<00:00,  4.74it/s]\n",
            "epoch: 007/030 | tr_loss: 6.8897e+00 | ndcg: 0.0190: 100%|██████████| 188/188 [00:39<00:00,  4.73it/s]\n",
            "epoch: 008/030 | tr_loss: 6.8764e+00 | ndcg: 0.0192: 100%|██████████| 188/188 [00:40<00:00,  4.67it/s]\n",
            "epoch: 009/030 | tr_loss: 6.8613e+00 | ndcg: 0.0194: 100%|██████████| 188/188 [00:39<00:00,  4.73it/s]\n",
            "epoch: 010/030 | tr_loss: 6.8438e+00 | ndcg: 0.0201: 100%|██████████| 188/188 [00:39<00:00,  4.71it/s]\n",
            "epoch: 011/030 | tr_loss: 6.8216e+00 | ndcg: 0.0209: 100%|██████████| 188/188 [00:39<00:00,  4.73it/s]\n",
            "epoch: 012/030 | tr_loss: 6.7938e+00 | ndcg: 0.0219: 100%|██████████| 188/188 [00:39<00:00,  4.72it/s]\n",
            "epoch: 013/030 | tr_loss: 6.7628e+00 | ndcg: 0.0225: 100%|██████████| 188/188 [00:39<00:00,  4.74it/s]\n",
            "epoch: 014/030 | tr_loss: 6.7288e+00 | ndcg: 0.0219: 100%|██████████| 188/188 [00:40<00:00,  4.65it/s]\n",
            "epoch: 015/030 | tr_loss: 6.6922e+00 | ndcg: 0.0216: 100%|██████████| 188/188 [00:40<00:00,  4.69it/s]\n",
            "epoch: 016/030 | tr_loss: 6.6540e+00 | ndcg: 0.0209: 100%|██████████| 188/188 [00:39<00:00,  4.73it/s]\n",
            "epoch: 017/030 | tr_loss: 6.6139e+00 | ndcg: 0.0205: 100%|██████████| 188/188 [00:39<00:00,  4.75it/s]\n",
            "epoch: 018/030 | tr_loss: 6.5723e+00 | ndcg: 0.0205: 100%|██████████| 188/188 [00:39<00:00,  4.75it/s]\n",
            "epoch: 019/030 | tr_loss: 6.5298e+00 | ndcg: 0.0204: 100%|██████████| 188/188 [00:40<00:00,  4.63it/s]\n",
            "epoch: 020/030 | tr_loss: 6.4864e+00 | ndcg: 0.0204: 100%|██████████| 188/188 [00:40<00:00,  4.69it/s]\n",
            "epoch: 021/030 | tr_loss: 6.4433e+00 | ndcg: 0.0207: 100%|██████████| 188/188 [00:40<00:00,  4.65it/s]\n",
            "epoch: 022/030 | tr_loss: 6.3999e+00 | ndcg: 0.0210: 100%|██████████| 188/188 [00:39<00:00,  4.72it/s]\n",
            "epoch: 023/030 | tr_loss: 6.3562e+00 | ndcg: 0.0212: 100%|██████████| 188/188 [00:40<00:00,  4.67it/s]\n",
            "epoch: 024/030 | tr_loss: 6.3130e+00 | ndcg: 0.0212: 100%|██████████| 188/188 [00:39<00:00,  4.71it/s]\n",
            "epoch: 025/030 | tr_loss: 6.2698e+00 | ndcg: 0.0213: 100%|██████████| 188/188 [00:40<00:00,  4.66it/s]\n",
            "epoch: 026/030 | tr_loss: 6.2261e+00 | ndcg: 0.0215: 100%|██████████| 188/188 [00:40<00:00,  4.70it/s]\n",
            "epoch: 027/030 | tr_loss: 6.1834e+00 | ndcg: 0.0215: 100%|██████████| 188/188 [00:40<00:00,  4.61it/s]\n",
            "epoch: 028/030 | tr_loss: 6.1399e+00 | ndcg: 0.0217: 100%|██████████| 188/188 [00:40<00:00,  4.69it/s]\n",
            "epoch: 029/030 | tr_loss: 6.0969e+00 | ndcg: 0.0218: 100%|██████████| 188/188 [00:40<00:00,  4.67it/s]\n",
            "epoch: 030/030 | tr_loss: 6.0539e+00 | ndcg: 0.0218: 100%|██████████| 188/188 [00:40<00:00,  4.70it/s]\n"
          ]
        }
      ],
      "source": [
        "best = 0\n",
        "for ep in range(config[\"epoch\"]):\n",
        "    tr_loss = train(model, tr_loader, criterion, optimizer, parser,\n",
        "                    prefix = \"epoch: {0:03d}/{1:03d}\".format(ep + 1, config[\"epoch\"]), leave = False)\n",
        "\n",
        "    ndcg_score = evaluate(model, tr_loader, parser, k = config[\"top_k\"],\n",
        "                          prefix = \"epoch: {0:03d}/{1:03d} | tr_loss: {2:.4e}\".format(ep + 1, config[\"epoch\"], tr_loss))\n",
        "\n",
        "    if best < ndcg_score:\n",
        "        best = ndcg_score\n",
        "        torch.save(model.state_dict(), config[\"model_path\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "140ca0d0",
      "metadata": {
        "id": "140ca0d0"
      },
      "source": [
        "# 7. Recommend by Best Model\n",
        "- 상위 50개 제품에 대해 추천 진행(50개 미만 추천은 오류 처리)\n",
        "- csv 확장자로 저장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJINPEPfmqjw",
        "outputId": "8f5397a1-1fcf-41db-ccdf-7874832c02cd"
      },
      "id": "IJINPEPfmqjw",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02247829314019395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ad5726a4-ff94-4244-8cf8-fd232294f3bf",
      "metadata": {
        "id": "ad5726a4-ff94-4244-8cf8-fd232294f3bf"
      },
      "outputs": [],
      "source": [
        "def recommend(model, data_loader, parser, k = 50, leave = True): #학습된 모델을 사용하여 추천을 수행\n",
        "    model.eval()\n",
        "    pred = {}\n",
        "\n",
        "    tr_pos, te_pos = parser.data\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, users in enumerate(tqdm(data_loader, total = len(data_loader), leave = leave, desc = \"recommend\")):\n",
        "            mat = parser.to_matrix(tr_pos, users)\n",
        "            mat = mat.to(device)\n",
        "\n",
        "            recon_mat = model(mat)\n",
        "            recon_mat = recon_mat.softmax(dim = 1)\n",
        "            recon_mat[mat == 1] = -1.\n",
        "            rec_list = recon_mat.argsort(dim = 1)\n",
        "\n",
        "            for user, rec in zip(users, rec_list):\n",
        "                up = rec[-k:].cpu().numpy()[::-1].tolist()\n",
        "                pred[user.item()] = up\n",
        "\n",
        "    submit = pd.DataFrame(columns=[\"user_id\", \"item_id\"])\n",
        "    user_list, item_list = [], []\n",
        "    for user, rec in tqdm(pred.items()):\n",
        "        user = parser.user_decoder[user]\n",
        "        for item in rec:\n",
        "            item = parser.item_decoder[item]\n",
        "            user_list.append(int(user))\n",
        "            item_list.append(int(item))\n",
        "    submit[\"user_id\"] = user_list\n",
        "    submit[\"item_id\"] = item_list\n",
        "    return submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5dba0816",
      "metadata": {
        "id": "5dba0816",
        "outputId": "87c5e90a-0497-4b8a-cb54-946fc0f5b792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(config[\"model_path\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ecaa2ae6",
      "metadata": {
        "id": "ecaa2ae6",
        "outputId": "797251dc-f769-4b99-8583-f3037802899d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "recommend: 100%|██████████| 188/188 [00:31<00:00,  5.98it/s]\n",
            "100%|██████████| 192403/192403 [00:04<00:00, 47732.68it/s]\n"
          ]
        }
      ],
      "source": [
        "submission = recommend(model, tr_loader, parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "61e688e1-1f93-4d1a-948c-49de0f2ce731",
      "metadata": {
        "id": "61e688e1-1f93-4d1a-948c-49de0f2ce731",
        "outputId": "0a42a136-764e-4b88-c87a-a2a220a24cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "submission.to_csv(config[\"submit_path\"], index=False)\n",
        "print(\"Done.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}